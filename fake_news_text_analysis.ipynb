{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417cf0d0",
   "metadata": {},
   "source": [
    "### üìò 1. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c6ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"/content/news.csv\")\n",
    "\n",
    "# Drop unnamed column if present\n",
    "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "# Map labels to binary\n",
    "df['label'] = df['label'].map({'FAKE': 0, 'REAL': 1})\n",
    "\n",
    "# Description\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nData Types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nClass Distribution:\\n\", df['label'].value_counts())\n",
    "print(\"\\nSample Text:\\n\", df['text'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158aa77",
   "metadata": {},
   "source": [
    "### üßπ 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880309f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.lower().strip()\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f826fd",
   "metadata": {},
   "source": [
    "### üìä 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df['text_length'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.xticks([0, 1], ['FAKE', 'REAL'])\n",
    "plt.title('Label Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['text_length'], bins=50, kde=True)\n",
    "plt.title('Text Length Distribution')\n",
    "plt.xlabel('Number of Words')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a571829",
   "metadata": {},
   "source": [
    "### üßµ 4. Parsing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['clean_text'].sample(5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be38a14",
   "metadata": {},
   "source": [
    "### üîç 5. Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['clean_text', 'text_length']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4790ce",
   "metadata": {},
   "source": [
    "### üîé 6. str_subset() Equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset_df = df[df['clean_text'].str.contains(\"breaking\", na=False)]\n",
    "print(subset_df[['clean_text']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f19093",
   "metadata": {},
   "source": [
    "### ‚úÖ 7. str_detect() Equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['contains_trump'] = df['clean_text'].str.contains(\"trump\", na=False).astype(int)\n",
    "print(df[['clean_text', 'contains_trump']].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb48dc",
   "metadata": {},
   "source": [
    "### üßµ 8. str_extract() Equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55761045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['first_word'] = df['clean_text'].str.extract(r'^(\\w+)', expand=False)\n",
    "print(df[['clean_text', 'first_word']].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23a84c",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è 9. Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_text = df['text'].iloc[10]\n",
    "print(\"Sample Text:\\n\", sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7330bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"\\b[A-Z][a-z]+\\b\", sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(Breaking|Exclusive)\", sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebaf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"[aeiou]{2,}\", sample_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cfb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"^Breaking\", sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41317a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"\\b(\\w+)\\s+\\1\\b\", sample_text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fe31c",
   "metadata": {},
   "source": [
    "### üî¢ 10. Logical Vector to Numerical Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['urgent_flag'] = df['clean_text'].str.contains(\"urgent\", na=False).astype(int)\n",
    "print(df[['clean_text', 'urgent_flag']].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2658e7",
   "metadata": {},
   "source": [
    "### üòä 11. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from textblob import TextBlob\n",
    "df['sentiment_score'] = df['clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "print(df[['clean_text', 'sentiment_score']].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5083452",
   "metadata": {},
   "source": [
    "### üî° 12. Bi-gram and N-gram Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(2, 3), max_features=20)\n",
    "X_ngrams = ngram_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "print(\"Top N-grams:\\n\", ngram_vectorizer.get_feature_names_out())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
